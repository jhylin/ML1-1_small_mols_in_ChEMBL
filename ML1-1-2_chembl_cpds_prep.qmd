---
title: Small molecules in ChEMBL database
subtitle: Series 1.1.2 - Exploratory data analysis and preprocessing in Polars dataframe library
author: Jennifer HY Lin
date: '2023-1-4'
date-modified: last-modified
draft: true
categories:
  - Machine learning projects
  - Polars
  - Python
  - Jupyter
  - ChEMBL database
  - Cheminformatics
jupyter: python3
bibliography: references.bib
---

##### **Import Polars and read parquet file**

```{python}
import polars as pl

# read parquet file as df
df_pa = pl.read_parquet("chembl_sm_mols.parquet")
df_pa
```

```{python}
df_pa.group_by("Max Phase").len()
```

Now I have the small molecules dataframe, I want to find out what types of physicochemical properties are there in the dataset.

```{python}
# Print all column names and data types 
print(df_pa.glimpse())
```

<br>

###### "Looking at some of the physicochemical properties in the dataset"

I've gone through the ChEMBL_31 schema documentation and ChEMBL database website to find out the meanings of some of the column names. The explanations for each term are adapted from ChEMBL_31 schema documentation (available as "Release notes" on the website at the time), or if definitions for certain terms are not available from the documentation, I resort to interpret them myself by going into "Dinstict compounds" section in the ChEMBL database.

The definitions for some of the listed physicochemical properties are:

**Max Phase** - Maximum phase of development reached for the compound (where 4 = approved). Null is where max phase has not yet been assigned.

**Bioactivities** - Various biological assays used for the compounds e.g. IC~50~, GI~50~, potency tests etc.

**AlogP** - Calculated partition coefficient

**HBA** - Number of hydrogen bond acceptors

**HBD** - Number of hydrogen bond donors

**#RO5 Violations** - Number of violations of Lipinski's rule-of-five, using HBA and HBD definitions

**Passes Ro3** - Indicating whether the compound passed the rule-of-three (MW \< 300, logP \< 3 etc)

**QED Weighted** - Weighted quantitative estimate of drug likeness [@Bickerton2012]

**Inorganic flag** - Indicating whether the molecule is inorganic (i.e., containing only metal atoms and \<2 carbon atoms), where 1 = inorganic compound and 0 = non-inorganic compound (-1 meaning preclinical compound or not a drug)

**Heavy Atoms** - Number of heavy (non-hydrogen) atoms

**CX Acidic pKa** - The most acidic pKa calculated using ChemAxon v17.29.0

**CX Basic pKa** - The most basic pKa calculated using ChemAxon v17.29.0

**CX LogP** - The calculated octanol/water partition coefficient using ChemAxon v17.29.0

**CX LogD** - The calculated octanol/water distribution coefficient at pH = 7.4 using ChemAxon v17.29.0

**Structure Type** - based on compound_structures table, where SEQ indicates an entry in the protein_therapeutics table instead, NONE indicates an entry in neither tables, e.g. structure unknown

**Inchi Key** - the IUPAC international chemical identifier key

The older version of this post has had a code section for changing the data types of several columns. I've found out that this is no longer needed as I've taken care of this in the first post when I've specifically stated the null_values (e.g. "None" and "") to be converted to"null" during `pl.read_csv()`. When the same dataframe df_pa is read here, you'll notice that the data type for each column should be how it should be, matching the data inside each column.

<br>

##### **Dealing with nulls**

I'm using `null_count()` to see the distributions of all null entries in the dataset.

```{python}
# Alternative code: df_pa.select(pl.all().null_count())
df_pa.null_count()
```

The following is basically several different ways to remove null values from the original dataset.

```{python}
## ---Drop all rows with null entries---
#df_pa.drop_nulls()

## Number of rows reduced to 2,645 - seems way too much...

## ---Restricting drop nulls to only subsets of nulls in strings ---
# import polars.selectors as cs
# df_pa.drop_nulls(subset=cs.string())

## Number of rows reduced to 17,735 - hmm... try other ways?

## ---Drop a row if all values are null---
# df_pa.filter(~pl.all_horizontal(pl.all().is_null()))

## No change in number of rows - meaning no one row contains all null values

## ---Restricting drop nulls to a specific column---
# df_pa.drop_nulls(subset="CX LogP")

## Number of rows reduced to 1,873,678
```

Initially, I've tried to remove all nulls first, then I realise that removing nulls above may not be the best way to prepare the data as all max phase 4 compounds are actually also removed completely! So what I'm going to do instead is to keep them by using `fill_null()` to replace all "null" as "0" (this'll only apply to all the integers or floats in the data).

```{python}
df_pa = df_pa.fill_null(0)
df_pa
```

```{python}
# Summary statistics for df_dn dataset
df_pa.describe()
```

<br>

##### **Looking at max phase and QED weighted**

To explore some of the physicochemical and molecular properties in the dataframe, "Max Phase" is one of the first few that I want to have a look. Each ChEMBL compound will have a max phase number from 0 to 4 (for this particularly dataset only, you'll notice that this can start from -1 in other ChEMBL datasets), where 4 means the compound is approved (e.g. a prescription medicine).

While looking at max phases, I'm thinking these compounds with max phase 0 could be a testing set for prediction of their max phase outcomes, while the max phase 4 compounds could be the training set for building a machine learning (ML) model. There are of course some obvious and potential flaws of splitting a dataset like this, please treat this as an exercise for demonstration only.

Below I'm checking that I do have max phases of molecules spanning across the entire range of 0 to 4.

```{python}
## Alternative code
# df_pa.group_by("Max Phase", maintain_order = True).agg(pl.len())
df_pa.group_by("Max Phase").len()
```

One of the other parameters I'm interested in is "QED Weighted" [@Bickerton2012]. It's a measure of druglikeness for small molecules based on the concept of desirability, which is based on a total of 8 different molecular properties. These molecular properties include molecular weight, ALogP, polar surface area, number of hydrogen bond acceptors, number of hydrogen bond donors, number of rotatable bonds, number of aromatic rings and structural alerts. It's normally recorded as a number ranging from 0 to 1, where 0 is the least druglike and 1 being the most druglike.

<br>

##### **Prepare data prior to running ML model**

The goal of this ML model is to answer this question - which physicochemical features will be suitable to predict whether a compound will enter max phase 4 or not? 

A rough plan at this stage is:

- to filter out max phase 4 and 0 compounds from the df_pa dataset

- to use "Max Phase" parameter as the target y variable for a logistic regression model because ultimately stakeholders are more likely to be interested in knowing which candidate compounds have the most likely chance to reach the final approved phase during a drug discovery project (*please bear in mind that this is of course way too simplified and not reflecting real-life scenarios...*)

- to use "Polar Surface Area", "HBA", "HBD", "#RO5 Violations", "QED Weighted", "CX LogP", "CX LogD" and "Heavy atoms" as the training features for building the ML model (*these molecular features are selected randomly and ideally I should include more... but the first three are newly added in this updated version*)

- to use max phase 0 compounds as the testing set since they are the ones not assigned with any max phase category yet

- to use max phase 4 compounds as the training set since they've reached the approved phase

- to build a confusion matrix in the end to see if the features selected may generate a somewhat reasonable model for predicting the outcomes of these small molecules

Downsides of this plan are (there are many...):

- the dataset used here will include some inorganic compounds (e.g. molecules containing metals)

- the dataset is likely not very-chemically-diverse 

- there are only a small number of max phase 4 compounds for model training (especially comparing with the "much larger" amount of max phase 0 compounds present)

- logistic regression may not be the best choice of ML model to start off with (but I just want to find out how it works at the time and hence I'm doing it here)

- other exploratory data analysis should be done really... e.g. how chemically diverse the dataset is?

- this is only an exercise or demonstration-like piece so will not be taking into account of many other important aspects of drug discovery e.g. what disorders or illnesses are we targeting? (is it an experimentally validated and suitable target?) and what have been done so far in the literatures? etc.

Firstly, I'm filtering out all the max phase 0 compounds and also all the max phase 4 compounds then save them in separate dataframes.

```{python}
# Selecting all max phase 0 molecules with their training features
df_0 = df_pa.filter((pl.col("Max Phase") == 0)).select([
  "ChEMBL ID", 
  "Type", 
  "Max Phase",
  "Polar Surface Area",
  "HBA",
  "HBD",
  "#RO5 Violations", 
  "QED Weighted", 
  "CX LogP", 
  "CX LogD", 
  "Heavy Atoms"
  ])
df_0  #1,826,345 mols
```

```{python}
# Selecting all max phase 4 molecules with their training features
df_4 = df_pa.filter((pl.col("Max Phase") == 4)).select([
      "ChEMBL ID", 
      "Type", 
      "Max Phase",
      "Polar Surface Area",
      "HBA",
      "HBD",
      "#RO5 Violations", 
      "QED Weighted", 
      "CX LogP", 
      "CX LogD", 
      "Heavy Atoms"
      ])
df_4  # 2,870 mols
```

```{python}
df_4.describe()
```

I have to go back to the first post at this point to change the data restriction criteria for the parquet file as I've found out in this step above that if I restrict data via inorganic flags, then it'll remove a lot of compounds with calculated physicochemical properties (because most of the ones in the data are preclinical compounds with inorganic flag of -1 or max phase 0 compounds; inorganic flag of 1 is inorganic ones and 0 should be the non-inorganic ones - I've updated its definition above too after re-checking the ChEMBL schema). For now, I'm restricting data via removing compounds with zero targets rather than via the inorganic flag, and this leaves us a set of max phase 4 compounds with their physicochemical properties calculated in ChEMBL (which is needed for training the model in the next post).

<br>

###### **Re-sampling via under-sampling - dealing with imbalanced training and test sets**

**The following needs to be updated**

Because of the large number of Max Phase 0 compounds present in the original dataset, I've randomly sampled about 950 small molecules from this group, so that there were similar amount of data in each group to avoid having an imbalanced dataset.

```{python}
df_s_0 = df_0.sample(n = 950, shuffle = True, seed = 0)
df_s_0
```

Since the plan was to use LR method for ML model, the y variable I was interested in was going to be a binary categorical variable - meaning it needed to be 0 (not approved) or 1 (approved). To do this, I've added a new column with a new name of "Max_Phase" and replace "4" as "1" by dividing the whole column by 4 to reach this new label.

```{python}
df_4_f = df_4.with_columns((pl.col("Max Phase") / 4).alias("Max_Phase"))
df_4_f
```

Then I changed the data type of "Max_Phase" from float to integer, so that the two different dataframes could be concatenated (which would only work if both were of same data types).

```{python}
df_4_f = df_4_f.with_columns((pl.col("Max_Phase")).cast(pl.Int64, strict = False))
df_4_f
```

Also I've created a new column with the same name of "Max_Phase" for Max phase 0 small molecules, so that the two dataframes could be combined (also needed to have exactly the same column names for it to work).

```{python}
df_s_0_f = df_s_0.with_columns((pl.col("Max Phase")).alias("Max_Phase"))
df_s_0_f
```

Then I combined df_s\_0_f (dataframe with max phase 0 compounds) and df_4\_f (dataframe with max phase 4 compounds).

```{python}
df_concat = pl.concat([df_s_0_f, df_4_f], how = "vertical",)
print(df_concat)
```

This df_concat dataset was checked to see it had all compounds in Max Phase 0 and 4 only. Note: Max Phase 4 (approved) compounds were re-labelled as Max_Phase = 1.

```{python}
df_concat.groupby("Max_Phase").count()
```

I then checked df_concat dataset only had small molecules to confirm what I've tried to achieve.

```{python}
# df_concat.groupby("Type").count()
```

So here we had the final version of the dataset, which I've renamed to df_ml to avoid confusion from the previous dataframes, before entering the ML phase.

```{python}
# Leave out ChEMBL ID and Type
df_ml = df_concat.select(["Max_Phase", 
                          "#RO5 Violations", 
                          "QED Weighted", 
                          "CX LogP", 
                          "CX LogD", 
                          "Heavy Atoms"]
                        )
df_ml
```

```{python}
# Check for any nulls in the dataset
df_ml.null_count()
```

```{python}
# Check data types in df_ml dataset
# Needed to be integers or floats for scikit-learn algorithms to work
df_ml.dtypes
```

``` {{python}}
# Note: exported df_ml dataframe as csv file for ML series 1.2.
df_ml.write_csv("df_ml.csv", sep = ",")
```
