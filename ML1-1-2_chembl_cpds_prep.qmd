---
title: Small molecules in ChEMBL database
subtitle: Series 1.1.2 - Exploratory data analysis and preprocessing in Polars dataframe library
author: Jennifer HY Lin
date: '2023-1-4'
date-modified: last-modified
draft: true
categories:
  - Machine learning projects
  - Polars
  - Python
  - Jupyter
  - ChEMBL database
  - Cheminformatics
jupyter: python3
bibliography: references.bib
---

##### **Import Polars and read parquet file**

```{python}
import polars as pl

# read parquet file as df
df_pa = pl.read_parquet("chembl_sm_mols.parquet")
df_pa
```

```{python}
# All max phase == 0 in this dataset!
df_pa.group_by("Max Phase").len()
```

Now I have the small molecules dataframe, I want to find out what types of physicochemical properties are there in the dataset.

```{python}
# Print all column names and data types 
print(df_pa.glimpse())
```

<br>

###### "Looking at some of the physicochemical properties in the dataset"

I've gone through the ChEMBL_31 schema documentation and ChEMBL database website to find out the meanings of some of the column names. The explanations for each term are adapted from ChEMBL_31 schema documentation (available as "Release notes" on the website at the time), or if definitions for certain terms are not available from the documentation, I resort to interpret them myself by going into "Dinstict compounds" section in the ChEMBL database.

The definitions for some of the listed physicochemical properties are:

**Max Phase** - Maximum phase of development reached for the compound (where 4 = approved). Null is where max phase has not yet been assigned.

**Bioactivities** - Various biological assays used for the compounds e.g. IC~50~, GI~50~, potency tests etc.

**AlogP** - Calculated partition coefficient

**HBA** - Number of hydrogen bond acceptors

**HBD** - Number of hydrogen bond donors

**#RO5 Violations** - Number of violations of Lipinski's rule-of-five, using HBA and HBD definitions

**Passes Ro3** - Indicating whether the compound passed the rule-of-three (MW \< 300, logP \< 3 etc)

**QED Weighted** - Weighted quantitative estimate of drug likeness [@Bickerton2012]

**Inorganic flag** - Indicating whether the molecule is inorganic (i.e., containing only metal atoms and \<2 carbon atoms), where 1 = inorganic compound and -1 = not inorganic compound (assuming 0 means it is neither case or yet to be assigned)

**Heavy Atoms** - Number of heavy (non-hydrogen) atoms

**CX Acidic pKa** - The most acidic pKa calculated using ChemAxon v17.29.0

**CX Basic pKa** - The most basic pKa calculated using ChemAxon v17.29.0

**CX LogP** - The calculated octanol/water partition coefficient using ChemAxon v17.29.0

**CX LogD** - The calculated octanol/water distribution coefficient at pH = 7.4 using ChemAxon v17.29.0

**Structure Type** - based on compound_structures table, where SEQ indicates an entry in the protein_therapeutics table instead, NONE indicates an entry in neither tables, e.g. structure unknown

**Inchi Key** - the IUPAC international chemical identifier key

The older version of this post has had a code section for changing the data types of several columns. I've found out that this is no longer needed as I've taken care of this in the first post when I've specifically stated the null_values (e.g. "None" and "") to be converted to"null" during `pl.read_csv()`. When the same dataframe df_pa is read here, you'll notice that the data type for each column should be how it should be, matching the data inside each column.

<br>

##### **Dealing with nulls**

I'm using `null_count()` to see the distributions of all null entries in the dataset.

```{python}
# Alternative code: df_pa.select(pl.all().null_count())
df_pa.null_count()
```

The following is basically several different ways to remove null values from the original dataset.

```{python}
## Drop all rows with null entries
#df_pa.drop_nulls()

# Number of rows reduced to 2,645 - seems way too much...

## Restricting drop nulls to only subsets of nulls in strings
# import polars.selectors as cs
# df_pa.drop_nulls(subset=cs.string())

# Number of rows reduced to 17,735 - hmm... try other ways?

## Drop a row if all values are null
# df_pa.filter(~pl.all_horizontal(pl.all().is_null()))

# No change in number of rows - meaning no one row contains all null values

# Restricting drop nulls to a specific column
# df_pa.drop_nulls(subset="CX LogP")

# Number of rows reduced to 1,873,678
```

Initially, I've tried to remove all nulls first, then I realise that removing nulls above may not be the best way to prepare the data as all max phase 4 compounds are actually also removed completely! So what I'm going to do instead is to keep them by using `fill_null()` to replace all "null" as "0" (this'll only apply to all the integers or floats in the data).

```{python}
df_pa = df_pa.fill_null(0)
df_pa
```

```{python}
# Summary statistics for df_dn dataset
df_pa.describe()
```

<br>

##### **Looking at max phase and QED weighted**

To explore some of the physicochemical and molecular properties in the dataframe, "Max Phase" is one of the first few that I want to have a look. Each ChEMBL compound will have a max phase number from 0 to 4 (for this particularly dataset only, you'll notice that this can start from -1 in other ChEMBL datasets), where 4 means the compound is approved (e.g. a prescription medicine).

While looking at max phases, I'm thinking these compounds with max phase 0 could be a testing set for prediction of their max phase outcomes, while the max phase 4 compounds could be the training set for building a machine learning model. There are of course some obvious and potential flaws of splitting a dataset like this, please treat this as an exercise for demonstration only.

Below I'm checking that I do have max phases of molecules spanning across the entire range of 0 to 4.

```{python}
## Alternative code
# df_pa.group_by("Max Phase", maintain_order = True).agg(pl.len())

df_pa.group_by("Max Phase").len()
```

One of the other parameters I'm interested in is "QED Weighted" [@Bickerton2012]. It's a measure of druglikeness for small molecules based on the concept of desirability, which is based on a total of 8 different molecular properties. These molecular properties include molecular weight, ALogP, polar surface area, number of hydrogen bond acceptors, number of hydrogen bond donors, number of rotatable bonds, number of aromatic rings and structural alerts. It's normally recorded as a number ranging from 0 to 1, where 0 is the least druglike and 1 being the most druglike.

<br>

##### **Prepare dataframe prior to running machine learning model**

**The following needs to be updated**

Before I got too carried away with further EDA, I wanted to get started on preparing a dataframe for the ML model. A rough plan at this stage was to filter out Max Phase 4 and 0 compounds. Max phase 0 compounds were the ones that were not assigned with any max phase numbers yet, so they would be ideal for use as the testing set. Another main idea was to use "Max Phase" parameter as the target y variable for a LR model, because ultimately stakeholders would be more interested in knowing which candidate compounds had the most likely chance to reach the final approved phase during a drug discovery and development project or otherwise. This would also provide a chance to potentially reduce the amount of resources and time required in such a complex and sophisticated matter.

The goal of this ML model was to answer this question: which physicochemical parameters would be the most suitable ones to predict whether a compound would enter max phase 4 (approved) or not? (implicitly, this might also help to predict which max phase 0 compounds would likely enter max phase 4 in the end)

I've then narrowed down the df_dn dataset to fulfill the following criteria:

-   Only small molecules present
-   Max phase of 0 and 4 only

Another reason behind choosing only small molecules that had max phase of 0 and 4 was that a confusion matrix could be built in the end to see if the parameters selected would give us a reasonably good model for predicting the outcomes of these small molecules.

For now, I've chosen the following columns (or physicochemical parameters) to appear in the interim df_0 and df_4 datasets.

```{python}
# Selecting Max phase 0 small molecules with desired parameters
df_0 = df_dn.filter(
    # (pl.col("Type") == "Small molecule") &
    (pl.col("Max Phase") == 0)
).select(["ChEMBL ID", 
          "Type", 
          "Max Phase",
          "#RO5 Violations", 
          "QED Weighted", 
          "CX LogP", 
          "CX LogD", 
          "Heavy Atoms"]
        )
df_0
```

```{python}
# Selecting Max phase 4 small molecules with desired parameters
df_4 = df_dn.filter(
    # (pl.col("Type") == "Small molecule") &
    (pl.col("Max Phase") == 4)
).select(["ChEMBL ID", 
          "Type", 
          "Max Phase",
          "#RO5 Violations", 
          "QED Weighted", 
          "CX LogP", 
          "CX LogD", 
          "Heavy Atoms"]
        )
df_4
```

The training features that are going to be used in building the machine learning model later are "#RO5 Violations", "QED Weighted", "CX LogP", "CX LogD" and "Heavy atoms". So only the null counts for these columns will be closely observed.

*please note these molecular features are selected randomly and are likely not ideal in real-life use case as this post is mainly about using Polars dataframe library with scikit_learn only*

<br>

###### **Re-sampling via under-sampling**

Because of the large number of Max Phase 0 compounds present in the original dataset, I've randomly sampled about 950 small molecules from this group, so that there were similar amount of data in each group to avoid having an imbalanced dataset.

```{python}
df_s_0 = df_0.sample(n = 950, shuffle = True, seed = 0)
df_s_0
```

Since the plan was to use LR method for ML model, the y variable I was interested in was going to be a binary categorical variable - meaning it needed to be 0 (not approved) or 1 (approved). To do this, I've added a new column with a new name of "Max_Phase" and replace "4" as "1" by dividing the whole column by 4 to reach this new label.

```{python}
df_4_f = df_4.with_columns((pl.col("Max Phase") / 4).alias("Max_Phase"))
df_4_f
```

Then I changed the data type of "Max_Phase" from float to integer, so that the two different dataframes could be concatenated (which would only work if both were of same data types).

```{python}
df_4_f = df_4_f.with_columns((pl.col("Max_Phase")).cast(pl.Int64, strict = False))
df_4_f
```

Also I've created a new column with the same name of "Max_Phase" for Max phase 0 small molecules, so that the two dataframes could be combined (also needed to have exactly the same column names for it to work).

```{python}
df_s_0_f = df_s_0.with_columns((pl.col("Max Phase")).alias("Max_Phase"))
df_s_0_f
```

Then I combined df_s\_0_f (dataframe with max phase 0 compounds) and df_4\_f (dataframe with max phase 4 compounds).

```{python}
df_concat = pl.concat([df_s_0_f, df_4_f], how = "vertical",)
print(df_concat)
```

This df_concat dataset was checked to see it had all compounds in Max Phase 0 and 4 only. Note: Max Phase 4 (approved) compounds were re-labelled as Max_Phase = 1.

```{python}
df_concat.groupby("Max_Phase").count()
```

I then checked df_concat dataset only had small molecules to confirm what I've tried to achieve.

```{python}
df_concat.groupby("Type").count()
```

So here we had the final version of the dataset, which I've renamed to df_ml to avoid confusion from the previous dataframes, before entering the ML phase.

```{python}
# Leave out ChEMBL ID and Type
df_ml = df_concat.select(["Max_Phase", 
                          "#RO5 Violations", 
                          "QED Weighted", 
                          "CX LogP", 
                          "CX LogD", 
                          "Heavy Atoms"]
                        )
df_ml
```

```{python}
# Check for any nulls in the dataset
df_ml.null_count()
```

```{python}
# Check data types in df_ml dataset
# Needed to be integers or floats for scikit-learn algorithms to work
df_ml.dtypes
```

``` {{python}}
# Note: exported df_ml dataframe as csv file for ML series 1.2.
df_ml.write_csv("df_ml.csv", sep = ",")
```
